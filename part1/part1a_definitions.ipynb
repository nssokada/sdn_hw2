{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seven free parameters in the hybrid model: $α^i_1$, $α^i_2$, $λ^i$, $β^i_1$, $β^i_2$, $w^i$ and $p^i$\n",
    "\n",
    "The i-th superscript indicates the parameter for the i-th participant. \n",
    "\n",
    "1. $α^i_1$ - the first-stage learning rate (0 $\\leq$ $α_1$ $\\leq$ 1): controls how much the model-free values of the first-stage actions are updated based on the reward prediciton errors from the first and second stage from previous trials.\n",
    "- When $α^i_1$ is close to 1, the model free value of the first-stage action is updated more based on new outcomes. \n",
    "- When $α^i_1$ is close to 0, the model free value of the first-stage action is updated less as the participant relied more on past experiences and is less influenced by recent outcomes. \n",
    "\n",
    "2. $α^i_2$ - the second-stage learning rate (0 $\\leq$ $α_2$ $\\leq$ 1): controls how much the model-free values of the second-stage actions are updated based on the second stage reward prediction errors from previous trials.\n",
    "- When $α^i_2$ is close to 1, the model free value of the second-stage action is updated more as the participant quickly learns which second-stage choice leads to rewards. \n",
    "- When $α^i_2$ is close to 0, the model free value of the second-stage action is updated less. \n",
    "\n",
    "3. $λ^i$ - the eligibility trace parameter (0 $\\leq$ $λ$ $\\leq$ 1): modulates how much the reward prediction error from the second stage affects the first-stage model-free values.\n",
    "- When $λ^i$ is close to 1, the model free value of the first stage action is updated more because the rewards prediction error from the second stage has a larger effect. \n",
    "- When $λ^i$ is close to 0, the model free value of the first stage action is updated less because the rewards prediction error from the second stage has a smaller effect. \n",
    "\n",
    "4. $β^i_1$ - the first-stage’s inverse temperature parameter, which determines the exploration rate (random vs consistent) at the first stage.  \n",
    "- When $β^i_1$ is high, the participant demonstrates more consistent choices in the first stage and keep choosing the action with the highest value. \n",
    "- When $β^i_1$ is low, the participent demonstrates more random choices in the first stage and is less influences by the known action values learned from previous trials. \n",
    "\n",
    "5. $β^i_2$ - the second-stage’s inverse temperature parameter, which determines the exploration rate (random vs consistent) at the second stage. \n",
    "- When $β^i_2$ is high, the participant demonstrates more consistent choices in the second stage and keep choosing the action with the highest value. \n",
    "- When $β^i_2$ is low, the participent demonstrates more random choices in the second stage and is less influences by the known action values learned from previous trials. \n",
    "\n",
    "6. $w^i$ - the model-based weight (0 $\\leq$ $w$ $\\leq$ 1): determines the relative contribution of model-based versus model-free value computations at the first stage.\n",
    "- A high $w^i$ (close to 1) means that the participant has a stronger reliance on model-based planning (considers the task transition structure and anticipates the reward outcomes).\n",
    "- A low $w^i$ (close to 0) means that the participant has a stronger reliance on model-free learning (learns from reward history without considering the transition structure). \n",
    "\n",
    "7. $p^i$ - the perseveration parameter, which measures the tendency to repeat the previous trial’s first-stage action in the next trial. \n",
    "- A high $p^i$ means that the participant is very likely to repeat the same choice from the previous trial regarless of reward or strategy (habitual repetition). \n",
    "- A low $p^i$ means that the participent is very unlikely to repeat the same choice from the previous trial and is very likely to chang their choice from trial to trial. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
